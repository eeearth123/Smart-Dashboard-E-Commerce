import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import joblib
import datetime
import os

# ==========================================
# 1. SETUP & CONFIGURATION (‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
# ==========================================
st.set_page_config(
    page_title="Olist Executive Cockpit",
    page_icon="‚úàÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style ‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á KPI
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 15px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. LOAD ASSETS (Update ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Model ‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏ï‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏°)
# ==========================================
@st.cache_resource
def load_data_and_model():
    data_dict = {}
    errors = []
    
    # Path Fix
    current_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(current_dir, 'olist_churn_model_best.pkl')
    features_path = os.path.join(current_dir, 'model_features_best.pkl')
    lite_data_path = os.path.join(current_dir, 'olist_dashboard_lite.csv')

    # 1. ‡πÇ‡∏´‡∏•‡∏î Model
    try:
        data_dict['model'] = joblib.load(model_path)
        data_dict['features'] = joblib.load(features_path)
    except Exception as e:
        errors.append(f"Model Error: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ ({e})")

    # 2. ‡πÇ‡∏´‡∏•‡∏î Data
    try:
        if os.path.exists(lite_data_path):
            df = pd.read_csv(lite_data_path)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
            if 'order_purchase_timestamp' in df.columns:
                df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])
            
            # [ADD] ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ (‡∏Å‡∏±‡∏ô Error)
            if 'payment_value' not in df.columns and 'price' in df.columns:
                df['payment_value'] = df['price'] + df.get('freight_value', 0)
            if 'freight_ratio' not in df.columns and 'freight_value' in df.columns:
                df['freight_ratio'] = df['freight_value'] / df['price']
                
            data_dict['df'] = df
        else:
            errors.append(f"Data Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà {lite_data_path}")
            
    except Exception as e:
        errors.append(f"Data Error: ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ({e})")
        
    return data_dict, errors

assets, load_errors = load_data_and_model()

# ‡πÄ‡∏ä‡πá‡∏Ñ Error
if load_errors:
    for err in load_errors:
        st.error(f"‚ö†Ô∏è {err}")
    if 'df' not in assets:
        st.stop()

# ==========================================
# 3. PREPARE DATA (‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ)
# ==========================================
df = assets['df'] 
model = assets.get('model')
feature_names = assets.get('features', [])

# 3.1 Predict Logic
if 'churn_probability' not in df.columns and model is not None:
    X_pred = pd.DataFrame(index=df.index)
    for col in feature_names:
        X_pred[col] = df[col] if col in df.columns else 0
    try:
        if hasattr(model, "predict_proba"):
            df['churn_probability'] = model.predict_proba(X_pred)[:, 1]
        else:
            df['churn_probability'] = model.predict(X_pred)
    except:
        df['churn_probability'] = 0.5 # Fallback

# -------------------------------------------------------------
# üîß [FIX] ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ Error is_churn ‡∏´‡∏≤‡∏¢
# -------------------------------------------------------------
if 'is_churn' not in df.columns:
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏â‡∏•‡∏¢‡∏à‡∏£‡∏¥‡∏á ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ "‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á AI" ‡πÅ‡∏ó‡∏ô
    # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô > 0.5 ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Churn (1), ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏Å‡πá‡πÄ‡∏õ‡πá‡∏ô Stay (0)
    df['is_churn'] = (df['churn_probability'] > 0.5).astype(int)
# -------------------------------------------------------------

# 3.2 Define Status Logic
if 'status' not in df.columns:
    def get_status(row):
        prob = row.get('churn_probability', 0)
        late = row.get('lateness_score', 0)
        
        if late > 3.0: return 'Lost (Late > 3x)'
        if prob > 0.75: return 'High Risk'
        if late > 1.5: return 'Warning (Late > 1.5x)'
        if prob > 0.5: return 'Medium Risk'
        return 'Active'
        
    df['status'] = df.apply(get_status, axis=1)

# ==========================================
# 4. NAVIGATION
# ==========================================
st.sidebar.title("‚úàÔ∏è Olist Cockpit")
page = st.sidebar.radio("Navigation", [
    "1. üìä Executive Summary", 
    "2. üîç Customer Detail", 
    "3. üéØ Action Plan",
    "4. üöõ Logistics Insights",
    "5. üè™ Seller Audit",
    "6. üîÑ Buying Cycle Analysis" # [NEW] ‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà
])

st.sidebar.markdown("---")
st.sidebar.info("Select a page to analyze different aspects of your business.")

# ==========================================
# PAGE 1: üìä Executive Summary (‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏° + ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≤‡∏î)
# ==========================================
if page == "1. üìä Executive Summary":
    st.title("üìä Executive Summary (Business Health)")
    
    # [ADD] ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Logic (‡πÉ‡∏™‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏°‡∏Ç‡∏≠)
    with st.expander("‚ÑπÔ∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ (Segmentation Logic) - ‡∏Å‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô"):
        st.markdown("""
        **‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö (Priority):**
        1. **üî¥ Lost:** ‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô 3 ‡πÄ‡∏ó‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡∏£‡∏≠‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥ (`Lateness > 3.0`) -> ‡πÄ‡∏•‡∏¥‡∏Å‡∏ã‡∏∑‡πâ‡∏≠‡∏ä‡∏±‡∏ß‡∏£‡πå
        2. **üü• High Risk:** ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ô‡∏≤‡∏ô‡∏°‡∏≤‡∏Å ‡πÅ‡∏ï‡πà **AI ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á > 75%** -> ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ã‡πà‡∏≠‡∏ô‡∏≠‡∏¢‡∏π‡πà
        3. **üüß Warning:** AI ‡∏ö‡∏≠‡∏Å‡πÇ‡∏≠‡πÄ‡∏Ñ ‡πÅ‡∏ï‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏´‡∏≤‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô 1.5 ‡πÄ‡∏ó‡πà‡∏≤ (`Lateness > 1.5`) -> ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
        4. **üü® Medium Risk:** ‡∏°‡∏≤‡∏ï‡∏£‡∏á‡πÄ‡∏ß‡∏•‡∏≤ ‡πÅ‡∏ï‡πà AI ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á 50-75%
        5. **üü© Active:** ‡∏°‡∏≤‡∏ï‡∏£‡∏á‡πÄ‡∏ß‡∏•‡∏≤ ‡πÅ‡∏•‡∏∞ AI ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≥
        """)

    # --- 1. FILTER SECTION (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì) ---
    with st.expander("üå™Ô∏è ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Filter)", expanded=False):
        all_cats = list(df['product_category_name'].unique()) if 'product_category_name' in df.columns else []
        selected_cats_p1 = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡∏ß‡πà‡∏≤‡∏á = ‡∏î‡∏π‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î):", all_cats, key="p1_cat_filter")
    
    if selected_cats_p1:
        df_display = df[df['product_category_name'].isin(selected_cats_p1)].copy()
        filter_label = f"‡∏´‡∏°‡∏ß‡∏î: {', '.join(selected_cats_p1[:3])}..."
    else:
        df_display = df.copy()
        filter_label = "‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó"

    st.caption(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•: **{filter_label}**")
    st.markdown("---")

    # --- 2. KPI CARDS (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì) ---
    total_customers = len(df_display)
    
    if total_customers > 0:
        risk_df = df_display[df_display['status'].isin(['High Risk', 'Warning (Late > 1.5x)'])]
        risk_count = len(risk_df)
        churn_rate = (risk_count / total_customers) * 100
        rev_at_risk = risk_df['payment_value'].sum() if 'payment_value' in df_display.columns else 0
        active_count = len(df_display[df_display['status'] == 'Active'])
        
        if 'cat_median_days' in df_display.columns:
            avg_cycle = df_display['cat_median_days'].mean()
            cycle_text = f"{avg_cycle:.0f} ‡∏ß‡∏±‡∏ô"
        else:
            cycle_text = "N/A"
    else:
        churn_rate, rev_at_risk, risk_count, active_count = 0, 0, 0, 0
        cycle_text = "-"

    k1, k2, k3, k4, k5 = st.columns(5)
    with k1: st.metric("üö® Churn Rate", f"{churn_rate:.1f}%")
    with k2: st.metric("üí∏ Revenue at Risk", f"R$ {rev_at_risk:,.0f}")
    with k3: st.metric("üë• Risk vs Total", f"{risk_count:,} / {total_customers:,}")
    with k4: st.metric("‚úÖ Active Customers", f"{active_count:,}")
    with k5: st.metric("üîÑ ‡∏£‡∏≠‡∏ö‡∏ã‡∏∑‡πâ‡∏≠‡∏õ‡∏Å‡∏ï‡∏¥ (Cycle)", cycle_text)

    st.markdown("---")

    # --- 3. CHARTS ---
    c1, c2 = st.columns([2, 1])
    
    with c1:
        # [RESTORE] ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Å‡∏£‡∏≤‡∏ü Forecast ‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
        st.subheader("üìà Churn Risk Trend & Forecast")
        if 'order_purchase_timestamp' in df_display.columns and not df_display.empty:
            df_display['month_year'] = df_display['order_purchase_timestamp'].dt.to_period('M').astype(str)
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
            trend_df = df_display.groupby('month_year')['churn_probability'].mean().reset_index()
            trend_df.columns = ['Date', 'Churn_Prob']
            trend_df['Type'] = 'Actual'
            trend_df['Date'] = pd.to_datetime(trend_df['Date']) # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô datetime
            
            if not trend_df.empty:
                last_date = trend_df['Date'].max()
                last_val = trend_df['Churn_Prob'].iloc[-1]
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Forecast 3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)
                anchor_df = pd.DataFrame({'Date': [last_date], 'Churn_Prob': [last_val], 'Type': ['Forecast']})
                future_dates = [last_date + pd.DateOffset(months=i) for i in range(1, 4)]
                future_vals = [last_val * (1 + 0.02*i) for i in range(1, 4)]
                future_df = pd.DataFrame({'Date': future_dates, 'Churn_Prob': future_vals, 'Type': ['Forecast']*3})
                
                full_trend = pd.concat([trend_df, anchor_df, future_df]).drop_duplicates()
                
                chart = alt.Chart(full_trend).mark_line(point=True).encode(
                    x=alt.X('Date', axis=alt.Axis(format='%b %Y', title='Timeline')),
                    y=alt.Y('Churn_Prob', axis=alt.Axis(format='%', title='Avg Churn Risk'), scale=alt.Scale(domain=[0.5, 1.0])),
                    color=alt.Color('Type', scale=alt.Scale(domain=['Actual', 'Forecast'], range=['#2980b9', '#e74c3c'])),
                    strokeDash=alt.condition(alt.datum.Type == 'Forecast', alt.value([5, 5]), alt.value([0])),
                    tooltip=['Date', alt.Tooltip('Churn_Prob', format='.1%'), 'Type']
                ).properties(height=350)
                st.altair_chart(chart, use_container_width=True)
            else:
                st.info("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü Trend")
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà")

    with c2:
        # (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
        st.subheader("üí∞ Revenue Share by Risk")
        if not df_display.empty:
            status_stats = df_display.groupby('status').agg({
                'customer_unique_id': 'count',
                'payment_value': 'sum'
            }).reset_index()
            status_stats.columns = ['Status', 'Count', 'Total_Revenue']
            
            domain = ['Active', 'Medium Risk', 'Warning (Late > 1.5x)', 'High Risk', 'Lost (Late > 3x)']
            range_ = ['#2ecc71', '#f1c40f', '#e67e22', '#e74c3c', '#95a5a6']
            
            donut = alt.Chart(status_stats).mark_arc(innerRadius=60).encode(
                theta=alt.Theta("Count", type="quantitative"), 
                color=alt.Color("Status", scale=alt.Scale(domain=domain, range=range_), legend=dict(orient='bottom')),
                tooltip=['Status', alt.Tooltip('Count', format=','), alt.Tooltip('Total_Revenue', format=',.0f')]
            ).properties(height=350)
            st.altair_chart(donut, use_container_width=True)
        else:
            st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•")

# ==========================================
# PAGE 2: üîç Customer Detail (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì 100%)
# ==========================================
elif page == "2. üîç Customer Detail":
    st.title("üîç ‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Customer Deep Dive)")
    
    with st.expander("üîé ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Filters)", expanded=True):
        f1, f2, f3 = st.columns(3)
        with f1:
            risk_opts = ['High Risk', 'Warning (Late > 1.5x)', 'Medium Risk', 'Lost (Late > 3x)', 'Active']
            sel_status = st.multiselect("1. ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:", risk_opts, default=['High Risk', 'Warning (Late > 1.5x)'])
        with f2:
            all_cats = list(df['product_category_name'].unique()) if 'product_category_name' in df.columns else []
            sel_cats = st.multiselect("2. ‡∏´‡∏°‡∏ß‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤:", all_cats)
        with f3:
            search_id = st.text_input("3. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ID:", "")

    mask = df['status'].isin(sel_status)
    if sel_cats: mask = mask & df['product_category_name'].isin(sel_cats)
    if search_id: mask = mask & df['customer_unique_id'].str.contains(search_id, case=False)
    filtered_df = df[mask]

    if 'product_category_name' in df.columns and not filtered_df.empty:
        cat_overview = df.groupby('product_category_name').agg({
            'customer_unique_id': 'count',
            'cat_median_days': 'mean'
        }).reset_index().rename(columns={'customer_unique_id': 'Total', 'cat_median_days': 'Cycle_Days'})
        
        cat_risk = filtered_df.groupby('product_category_name').agg({
            'customer_unique_id': 'count'
        }).reset_index().rename(columns={'customer_unique_id': 'Risk_Count'})
        
        cat_stats = pd.merge(cat_risk, cat_overview, on='product_category_name', how='left')
        cat_stats['Risk_Pct'] = cat_stats['Risk_Count'] / cat_stats['Total']
        cat_stats = cat_stats.sort_values('Risk_Count', ascending=False)

        col_c, col_t = st.columns([1.5, 2.5])
        with col_c:
            st.subheader("üìä Top 10 ‡∏´‡∏°‡∏ß‡∏î‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á")
            base = alt.Chart(cat_stats.head(10)).encode(y=alt.Y('product_category_name', sort='-x', title=None))
            b_total = base.mark_bar(color='#f0f2f6').encode(x='Total', tooltip=['product_category_name', 'Total'])
            b_risk = base.mark_bar(color='#e74c3c').encode(x='Risk_Count', tooltip=['Risk_Count', 'Risk_Pct'])
            st.altair_chart(b_total + b_risk, use_container_width=True)

        with col_t:
            st.subheader("üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î")
            st.dataframe(cat_stats, use_container_width=True, hide_index=True)

    st.markdown("---")
    st.subheader(f"üìÑ ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ({len(filtered_df):,} ‡∏Ñ‡∏ô)")
    show_cols = ['customer_unique_id', 'status', 'churn_probability', 'lateness_score', 'cat_median_days', 'payment_value', 'product_category_name']
    final_cols = [c for c in show_cols if c in df.columns]
    
    st.dataframe(
        filtered_df[final_cols].sort_values('churn_probability', ascending=False),
        column_config={
            "churn_probability": st.column_config.ProgressColumn("Risk", format="%.2f", min_value=0, max_value=1),
            "lateness_score": st.column_config.NumberColumn("Late Score", format="%.1fx")
        },
        use_container_width=True
    )

# ==============================================================================
# PAGE 3: üéØ Action Plan (‡πÄ‡∏û‡∏¥‡πà‡∏° Loading State)
# ==============================================================================
elif page == "3. üéØ Action Plan":
    import time # ‡πÄ‡∏û‡∏¥‡πà‡∏° library ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤

    st.title("üéØ Action Plan & Simulator")
    st.markdown("### ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (Targeted Strategy)")
    
    # ---------------------------------------------------------
    # 0. PREPARE DATA & MULTI-FILTER
    # ---------------------------------------------------------
    if 'df_display' not in locals():
        df_display = df.copy()

    with st.container():
        st.markdown("##### üîé ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÇ‡∏ü‡∏Å‡∏±‡∏™ (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏±‡∏ô)")
        
        all_cats = sorted(list(df['product_category_name'].unique())) if 'product_category_name' in df.columns else []
        
        sel_cats_p3 = st.multiselect(
            "‡∏´‡∏°‡∏ß‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ (‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏ß‡πà‡∏≤‡∏á = ‡∏î‡∏π‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î):", 
            all_cats, 
            key="p3_cat_multiselect"
        )
        
        if sel_cats_p3:
            df_p3 = df_display[df_display['product_category_name'].isin(sel_cats_p3)].copy()
            filter_msg = f"‡∏´‡∏°‡∏ß‡∏î: {', '.join(sel_cats_p3[:3])}{'...' if len(sel_cats_p3)>3 else ''}"
        else:
            df_p3 = df_display.copy()
            filter_msg = "‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏´‡∏°‡∏ß‡∏î"

        total_pop = len(df_p3)
        avg_ltv = df_p3['payment_value'].mean() if 'payment_value' in df_p3.columns else 150
        
        c1, c2 = st.columns([3, 1])
        with c1:
            st.info(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: **{filter_msg}**")
        with c2:
            st.metric("üë• ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ", f"{total_pop:,} ‡∏Ñ‡∏ô", help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ï‡∏≤‡∏° Filter ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")

    st.markdown("---")

    # ---------------------------------------------------------
    # 1. HELPER FUNCTION (‡πÄ‡∏û‡∏¥‡πà‡∏° Loading Spinner ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ)
    # ---------------------------------------------------------
    def render_strategy_story(title, icon, target_df, total_pop, strategy_name, default_cost, compare_col=None, good_value=None, bad_values=None, rec_text=""):
        n_target = len(target_df)
        pct_problem = (n_target / total_pop) * 100 if total_pop > 0 else 0
        
        # --- UI ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ---
        st.subheader(f"{icon} {title}")
        c_prob, c_sol, c_res = st.columns([1, 1.3, 1])
        
        with c_prob:
            st.info(f"**üìâ ‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏û‡∏ö {n_target:,} ‡∏Ñ‡∏ô\n({pct_problem:.1f}% ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ)")
            st.progress(min(pct_problem / 100, 1.0))
            st.caption("‡πÅ‡∏ñ‡∏ö‡∏™‡∏µ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤")

        with c_sol:
            st.markdown(f"**üõ†Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: {strategy_name}**")
            st.write(rec_text)
            st.markdown("---")
            
            # ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ Cost
            cost = st.number_input(f"‡∏á‡∏ö‡∏ï‡πà‡∏≠‡∏´‡∏±‡∏ß (R$)", value=default_cost, min_value=1, step=1, key=f"cost_{title}")
            
            # --- ü§ñ ADVANCED AI LOGIC ---
            max_potential = 5
            ai_msg = ""
            
            if compare_col and good_value is not None and 'churn_probability' in df_p3.columns:
                try:
                    if bad_values: bad_group = df_p3[df_p3[compare_col].isin(bad_values)]
                    else: bad_group = target_df
                    bad_churn = bad_group['churn_probability'].mean() if not bad_group.empty else 0.8
                    
                    if isinstance(good_value, list): good_group = df_p3[df_p3[compare_col].isin(good_value)]
                    elif isinstance(good_value, (int, float)): good_group = df_p3[df_p3[compare_col] <= good_value]
                    else: good_group = df_p3[df_p3[compare_col] == good_value]
                    good_churn = good_group['churn_probability'].mean() if not good_group.empty else 0.4
                    
                    uplift = (bad_churn - good_churn) * 100
                    max_potential = max(int(uplift * 0.5), 1) 
                except: pass

            if cost < 5:
                realistic_rate = min(max_potential, 3)
                constraint_msg = " (‡∏á‡∏ö‡∏ô‡πâ‡∏≠‡∏¢ = ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≥‡∏Å‡∏±‡∏î)"
            elif cost < 15:
                realistic_rate = min(max_potential, 10)
                constraint_msg = " (‡∏á‡∏ö‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á)"
            else:
                realistic_rate = max_potential
                constraint_msg = " (‡∏á‡∏ö‡∏™‡∏π‡∏á = ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà)"
            
            st.markdown(f"**ü§ñ AI Prediction:** `{realistic_rate}%`")
            st.caption(f"(Max Potential: {max_potential}% {constraint_msg})")
            
            lift = st.slider(f"‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (%)", 1, 100, realistic_rate, key=f"lift_{title}")

        # --- ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡πÄ‡∏û‡∏¥‡πà‡∏° Spinner ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ) ---
        with c_res:
            # üü¢ ‡πÉ‡∏™‡πà Loading Spinner ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ User ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
            with st.spinner('‚ö° AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤...'):
                time.sleep(0.4) # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 0.4 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏±‡∏ô‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô (UX Trick)
                
                budget = n_target * cost
                saved_users = int(n_target * (lift / 100))
                revenue = saved_users * avg_ltv
                roi = ((revenue - budget) / budget) * 100 if budget > 0 else 0
                
                st.success(f"**üöÄ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**")
                st.metric("üí∏ ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì", f"R$ {budget:,.0f}")
                st.metric("üë• ‡∏î‡∏∂‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏Ñ‡∏∑‡∏ô", f"{saved_users:,} ‡∏Ñ‡∏ô")
                st.metric("üí∞ ‡∏Å‡∏≥‡πÑ‡∏£ (ROI)", f"{roi:+.0f}%", delta=f"+{revenue:,.0f}")
                
                if roi > 0:
                    st.caption("‚úÖ **‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô!**")
                else:
                    st.error("‚ö†Ô∏è **‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô!** (‡∏•‡∏≠‡∏á‡∏•‡∏î‡∏á‡∏ö ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)")

    # ---------------------------------------------------------
    # 2. STRATEGY TABS
    # ---------------------------------------------------------
    tab1, tab2, tab3, tab4 = st.tabs([
        "üí≥ 1. ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏á‡∏¥‡∏ô", 
        "üöö 2. ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏™‡πà‡∏á‡πÅ‡∏û‡∏á", 
        "‚ù§Ô∏è 3. ‡∏á‡πâ‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤",
        "üõçÔ∏è 4. ‡∏Ç‡∏≤‡∏¢‡∏û‡πà‡∏ß‡∏á‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á"
    ])

    with tab1:
        if 'payment_type' in df_p3.columns:
            target = df_p3[df_p3['payment_type'].isin(['credit_card', 'boleto'])]
            render_strategy_story(
                "‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏á‡∏¥‡∏ô (Payment Risk)", "üí≥", target, total_pop,
                "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Cash ‡πÄ‡∏õ‡πá‡∏ô Voucher", 20, 
                'payment_type', ['voucher'], ['credit_card', 'boleto'],
                "‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏à‡πà‡∏≤‡∏¢‡∏ö‡∏±‡∏ï‡∏£‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï/‡πÇ‡∏≠‡∏ô ‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™ Churn ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ô‡∏ñ‡∏∑‡∏≠ Voucher ‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏Å‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ã‡∏∑‡πâ‡∏≠‡∏ã‡πâ‡∏≥\n\nüëâ **Action:** ‡πÄ‡∏™‡∏ô‡∏≠ Cashback 5% ‡πÄ‡∏Ç‡πâ‡∏≤ Wallet ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°"
            )
        else: st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 'payment_type'")

    with tab2:
        if 'freight_ratio' in df_p3.columns:
            target = df_p3[df_p3['freight_ratio'] > 0.2]
            avg_freight = target['freight_value'].mean() if not target.empty else 20
            render_strategy_story(
                "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏™‡πà‡∏á‡πÅ‡∏û‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡∏£‡∏±‡∏ö‡πÑ‡∏´‡∏ß (Freight Pain)", "üöö", target, total_pop,
                "‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏™‡πà‡∏á (Free Shipping)", int(avg_freight), 
                'freight_ratio', 0.1, None,
                f"‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ‡∏•‡∏±‡∏á‡πÄ‡∏•‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡∏™‡πà‡∏á‡πÅ‡∏û‡∏á (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ R$ {avg_freight:.0f})\n\nüëâ **Action:** ‡πÅ‡∏à‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏™‡πà‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÅ‡∏£‡∏á‡∏ï‡πâ‡∏≤‡∏ô (Friction) ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à"
            )
        else: st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 'freight_ratio'")

    with tab3:
        if 'delay_days' in df_p3.columns:
            target = df_p3[df_p3['delay_days'] > 0]
            render_strategy_story(
                "‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÇ‡∏î‡∏ô‡πÄ‡∏ó/‡∏Ç‡∏≠‡∏á‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤ (Delay Recovery)", "‚ù§Ô∏è", target, total_pop,
                "SMS ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏© + ‡∏Ñ‡∏π‡∏õ‡∏≠‡∏á", 15, 
                'delay_days', 0, None,
                "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤‡∏ó‡∏≥‡∏•‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÉ‡∏à\n\nüëâ **Action:** ‡∏™‡πà‡∏á SMS ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡∏ä‡πâ‡∏≤ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏ô‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î‡∏û‡∏¥‡πÄ‡∏®‡∏©"
            )
        else: st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 'delay_days'")

    with tab4:
        if 'cat_churn_risk' in df_p3.columns:
            target = df_p3[df_p3['cat_churn_risk'] > 0.8]
            render_strategy_story(
                "‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ã‡∏∑‡πâ‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á (High Risk)", "üõçÔ∏è", target, total_pop,
                "Cross-sell ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ã‡∏∑‡πâ‡∏≠‡∏á‡πà‡∏≤‡∏¢", 10, 
                'cat_churn_risk', 0.5, None,
                "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ö‡∏≤‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏Ñ‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏à‡∏ö (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ü‡∏≠‡∏£‡πå‡∏ô‡∏¥‡πÄ‡∏à‡∏≠‡∏£‡πå) ‡∏ó‡∏≥‡πÉ‡∏´‡πâ Churn ‡∏™‡∏π‡∏á\n\nüëâ **Action:** ‡∏¢‡∏¥‡∏á‡πÅ‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏û‡πà‡∏ß‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏°‡∏ß‡∏î‡∏Ç‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏ö‡πâ‡∏≤‡∏ô (Housewares) ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏ã‡πâ‡∏≥‡∏ö‡πà‡∏≠‡∏¢‡πÜ"
            )
        else: st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 'cat_churn_risk'")
# ==============================================================================
# PAGE 4: üöõ Logistics Insights (State Map & City Details)
# ==============================================================================
elif page == "4. üöõ Logistics Insights":
    import pydeck as pdk

    st.title("üöõ Logistics Insights")
    st.markdown("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏ô‡∏™‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô ‡∏£‡∏≤‡∏¢‡∏£‡∏±‡∏ê (Map) ‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡πÄ‡∏°‡∏∑‡∏≠‡∏á (Table)")

    # ---------------------------------------------------------
    # 0. PREPARE DATA & FILTER
    # ---------------------------------------------------------
    if 'customer_state' not in df.columns:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏±‡∏ê (customer_state)")
        st.stop()

    # 1. Filter ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
    with st.container():
        all_cats = sorted(list(df['product_category_name'].unique())) if 'product_category_name' in df.columns else []
        sel_cats_p4 = st.multiselect("üì¶ ‡∏Å‡∏£‡∏≠‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤:", all_cats, key="p4_cat_filter")
        
        if sel_cats_p4:
            df_logistics = df[df['product_category_name'].isin(sel_cats_p4)].copy()
            filter_msg = f"‡∏´‡∏°‡∏ß‡∏î: {', '.join(sel_cats_p4[:3])}..."
        else:
            df_logistics = df.copy()
            filter_msg = "‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏´‡∏°‡∏ß‡∏î"

    # ---------------------------------------------------------
    # 1. DATA PROCESSING (STATE LEVEL)
    # ---------------------------------------------------------
    # ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏£‡∏±‡∏ê‡∏ö‡∏£‡∏≤‡∏ã‡∏¥‡∏• (Latitude, Longitude)
    brazil_states_coords = {
        'AC': [-9.02, -70.81], 'AL': [-9.57, -36.78], 'AM': [-3.41, -65.85],
        'AP': [0.90, -52.00], 'BA': [-12.58, -41.70], 'CE': [-5.49, -39.32],
        'DF': [-15.79, -47.88], 'ES': [-19.18, -40.30], 'GO': [-15.82, -49.84],
        'MA': [-5.19, -45.16], 'MG': [-19.81, -43.95], 'MS': [-20.77, -54.78],
        'MT': [-12.96, -56.92], 'PA': [-6.31, -52.46], 'PB': [-7.24, -36.78],
        'PE': [-8.81, -36.95], 'PI': [-7.71, -42.72], 'PR': [-25.25, -52.02],
        'RJ': [-22.90, -43.17], 'RN': [-5.40, -36.95], 'RO': [-11.50, -63.58],
        'RR': [2.73, -62.07], 'RS': [-30.03, -51.22], 'SC': [-27.24, -50.21],
        'SE': [-10.57, -37.38], 'SP': [-23.55, -46.63], 'TO': [-10.17, -48.33]
    }

    # Group Data ‡∏£‡∏≤‡∏¢‡∏£‡∏±‡∏ê
    state_metrics = df_logistics.groupby('customer_state').agg({
        'payment_value': 'sum',                 # ‡πÄ‡∏á‡∏¥‡∏ô‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô
        'delivery_days': 'mean',                # ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Å‡∏µ‡πà‡∏ß‡∏±‡∏ô
        'delay_days': lambda x: (x > 0).sum(),  # ‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤‡∏Å‡∏µ‡πà‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå (Count Late)
        'churn_probability': 'mean',            # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        'order_purchase_timestamp': 'count'     # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå
    }).reset_index().rename(columns={'order_purchase_timestamp': 'total_orders'})

    # Map Lat/Long
    state_metrics['lat'] = state_metrics['customer_state'].map(lambda x: brazil_states_coords.get(x, [0,0])[0])
    state_metrics['lon'] = state_metrics['customer_state'].map(lambda x: brazil_states_coords.get(x, [0,0])[1])

    # ---------------------------------------------------------
    # 2. MAP & STATE TABLE
    # ---------------------------------------------------------
    st.markdown("---")
    
    # ‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Zoom
    col_sel, col_kpi1, col_kpi2, col_kpi3 = st.columns([1.5, 1, 1, 1])
    
    with col_sel:
        zoom_state = st.selectbox("üîç ‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏£‡∏±‡∏ê (Zoom):", ["All (‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®)"] + sorted(state_metrics['customer_state'].unique()))
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏°‡∏∏‡∏°‡∏Å‡∏•‡πâ‡∏≠‡∏á (View State)
    if zoom_state != "All (‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®)":
        display_data = state_metrics[state_metrics['customer_state'] == zoom_state]
        if not display_data.empty:
            view_lat = display_data['lat'].values[0]
            view_lon = display_data['lon'].values[0]
            view_zoom = 6 # ‡∏ã‡∏π‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏Å‡∏•‡πâ‡πÜ
        else:
            view_lat, view_lon, view_zoom = -14.2350, -51.9253, 3.5
    else:
        display_data = state_metrics
        view_lat, view_lon, view_zoom = -14.2350, -51.9253, 3.5

    # KPI Summary
    total_rev = display_data['payment_value'].sum()
    avg_del = display_data['delivery_days'].mean()
    total_late = display_data['delay_days'].sum()

    with col_kpi1: st.metric("üí∞ ‡πÄ‡∏á‡∏¥‡∏ô‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô", f"R$ {total_rev:,.0f}")
    with col_kpi2: st.metric("üöö ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", f"{avg_del:.1f} ‡∏ß‡∏±‡∏ô")
    with col_kpi3: st.metric("‚ö†Ô∏è ‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤ (Late)", f"{total_late:,} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á", delta_color="inverse")

    # --- ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏±‡∏ê ---
    c_map, c_state_table = st.columns([2, 1])

    with c_map:
        st.subheader(f"üó∫Ô∏è ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà ({zoom_state})")
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏µ‡∏ß‡∏á‡∏Å‡∏•‡∏°: ‡πÅ‡∏î‡∏á=‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏°‡∏≤‡∏Å, ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á=‡∏Å‡∏•‡∏≤‡∏á, ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß=‡∏î‡∏µ
        state_metrics['color'] = state_metrics['churn_probability'].apply(
            lambda x: [231, 76, 60, 200] if x > 0.8 else ([241, 196, 15, 200] if x > 0.5 else [46, 204, 113, 200])
        )
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏ß‡∏á‡∏Å‡∏•‡∏°‡∏ï‡∏≤‡∏°‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô
        max_val = state_metrics['payment_value'].max()
        # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏®‡∏π‡∏ô‡∏¢‡πå
        if max_val > 0:
            state_metrics['radius'] = state_metrics['payment_value'] / max_val * 400000
        else:
            state_metrics['radius'] = 10000

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Layer
        layer = pdk.Layer(
            "ScatterplotLayer",
            state_metrics,
            get_position='[lon, lat]',
            get_color='color',
            get_radius='radius',
            pickable=True,
            opacity=0.8,
            stroked=True,
            filled=True,
            radius_min_pixels=5,
            radius_max_pixels=60,
        )

        tooltip = {
            "html": "<b>‡∏£‡∏±‡∏ê: {customer_state}</b><br/>"
                    "üí∞ ‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô: R$ {payment_value:,.0f}<br/>"
                    "üöö ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {delivery_days:.1f} ‡∏ß‡∏±‡∏ô<br/>"
                    "‚ö†Ô∏è ‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤: {delay_days} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á<br/>"
                    "üìâ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á: {churn_probability:.2f}",
            "style": {"backgroundColor": "steelblue", "color": "white"}
        }

        # ‡πÉ‡∏ä‡πâ map_style ‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏£‡∏∑‡∏≠ 'light' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
        r = pdk.Deck(
            layers=[layer],
            initial_view_state=pdk.ViewState(latitude=view_lat, longitude=view_lon, zoom=view_zoom, pitch=20),
            tooltip=tooltip,
            map_provider='carto',
            map_style='light' # ‡πÉ‡∏ä‡πâ Carto Light ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á (‡πÇ‡∏´‡∏•‡∏î‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Mapbox)
        )
        st.pydeck_chart(r)

    with c_state_table:
        st.subheader("üö® ‡∏£‡∏±‡∏ê‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (Top Issues)")
        sort_mode = st.radio("‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°:", ["‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î (Late Count)", "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (Risk)"], horizontal=True)
        
        if "‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤" in sort_mode:
            top_issues = state_metrics.sort_values('delay_days', ascending=False).head(10)
        else:
            top_issues = state_metrics.sort_values('churn_probability', ascending=False).head(10)

        st.dataframe(
            top_issues[['customer_state', 'payment_value', 'delivery_days', 'delay_days', 'churn_probability']],
            column_config={
                "customer_state": "‡∏£‡∏±‡∏ê",
                "payment_value": st.column_config.NumberColumn("‡πÄ‡∏á‡∏¥‡∏ô‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô", format="R$ %.0f"),
                "delivery_days": st.column_config.NumberColumn("‡∏™‡πà‡∏á (‡∏ß‡∏±‡∏ô)", format="%.1f"),
                "delay_days": st.column_config.NumberColumn("‡∏ä‡πâ‡∏≤ (‡∏Ñ‡∏£‡∏±‡πâ‡∏á)"),
                "churn_probability": st.column_config.ProgressColumn("‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á", format="%.2f", min_value=0, max_value=1)
            },
            hide_index=True,
            use_container_width=True
        )

    # ---------------------------------------------------------
    # 3. CITY LEVEL DETAILS (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏≠)
    # ---------------------------------------------------------
    st.markdown("---")
    st.subheader("üèôÔ∏è ‡πÄ‡∏à‡∏≤‡∏∞‡∏•‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡πÄ‡∏°‡∏∑‡∏≠‡∏á (City Drill-down)")
    st.caption("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏°‡∏∑‡∏≠‡∏á (‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)")

    if 'customer_city' in df_logistics.columns:
        # Group Data ‡∏£‡∏≤‡∏¢‡πÄ‡∏°‡∏∑‡∏≠‡∏á
        city_metrics = df_logistics.groupby(['customer_state', 'customer_city']).agg({
            'customer_unique_id': 'count',          # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
            'payment_value': 'sum',                 # ‡πÄ‡∏á‡∏¥‡∏ô‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô
            'delivery_days': 'mean',                # ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
            'delay_days': lambda x: (x > 0).sum(),  # ‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤‡∏Å‡∏µ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á
            'churn_probability': 'mean'             # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á
        }).reset_index()
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡∏≠‡∏≠‡∏Å (‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ Data > 1) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢
        city_metrics = city_metrics[city_metrics['customer_unique_id'] >= 2]
        
        # Filter ‡∏ï‡∏≤‡∏°‡∏£‡∏±‡∏ê‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ã‡∏π‡∏°‡∏£‡∏±‡∏ê)
        if zoom_state != "All (‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®)":
            city_display = city_metrics[city_metrics['customer_state'] == zoom_state]
            st.info(f"üìç ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÉ‡∏ô‡∏£‡∏±‡∏ê: **{zoom_state}**")
        else:
            city_display = city_metrics
            st.info("üìç ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® (Top 50 ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤)")

        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô)
        city_display = city_display.sort_values('delay_days', ascending=False).head(50)

        st.dataframe(
            city_display,
            column_config={
                "customer_state": "‡∏£‡∏±‡∏ê",
                "customer_city": "‡πÄ‡∏°‡∏∑‡∏≠‡∏á",
                "customer_unique_id": st.column_config.NumberColumn("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤"),
                "payment_value": st.column_config.NumberColumn("‡∏¢‡∏≠‡∏î‡πÄ‡∏á‡∏¥‡∏ô‡∏£‡∏ß‡∏°", format="R$ %.0f"),
                "delivery_days": st.column_config.NumberColumn("‡∏™‡πà‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (‡∏ß‡∏±‡∏ô)", format="%.1f"),
                "delay_days": st.column_config.NumberColumn("‡∏™‡πà‡∏á‡∏ä‡πâ‡∏≤ (‡∏Ñ‡∏£‡∏±‡πâ‡∏á)"),
                "churn_probability": st.column_config.ProgressColumn("‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Avg)", format="%.2f", min_value=0, max_value=1)
            },
            hide_index=True,
            use_container_width=True
        )
    else:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏°‡∏∑‡∏≠‡∏á (customer_city)")
# ==========================================
# PAGE 5: üè™ Seller Audit (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
# ==========================================
elif page == "5. üè™ Seller Audit":
    st.title("üè™ Seller Watchlist")
    if 'seller_id' not in df.columns:
        st.error("No seller data")
        st.stop()
        
    seller_stats = df.groupby('seller_id').agg({
        'customer_unique_id': 'count', 'churn_probability': 'mean',
        'review_score': 'mean', 'payment_value': 'sum'
    }).reset_index()
    
    bad_sellers = seller_stats[seller_stats['customer_unique_id'] >= 5].sort_values('churn_probability', ascending=False).head(50)
    
    k1, k2, k3 = st.columns(3)
    k1.metric("üö® ‡∏£‡πâ‡∏≤‡∏ô‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á", f"{len(bad_sellers)} ‡∏£‡πâ‡∏≤‡∏ô")
    k2.metric("üí∏ ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ", f"R$ {bad_sellers['payment_value'].sum():,.0f}")
    k3.metric("üìâ Avg Churn", f"{bad_sellers['churn_probability'].mean()*100:.1f}%")
    
    st.dataframe(bad_sellers.head(20), use_container_width=True, hide_index=True)
    
    st.markdown("### üîç Quality vs Risk")
    chart = alt.Chart(seller_stats[seller_stats['customer_unique_id'] >= 5]).mark_circle(color='#e74c3c').encode(
        x='review_score', y='churn_probability', size='payment_value',
        tooltip=['seller_id', 'review_score', 'churn_probability']
    ).properties(height=350).interactive()
    st.altair_chart(chart, use_container_width=True)

# ==========================================
# PAGE 6: üîÑ Buying Cycle Analysis (‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Ç‡∏≠)
# ==========================================
elif page == "6. üîÑ Buying Cycle Analysis":
    st.title("üîÑ Buying Cycle Analysis")
    st.markdown("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠: **‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÑ‡∏´‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏ã‡πâ‡∏≥‡∏ö‡πà‡∏≠‡∏¢? ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏•‡∏ó‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô?**")
    
    avg_cycle = df['cat_median_days'].mean() if 'cat_median_days' in df.columns else 0
    avg_late = df['lateness_score'].mean() if 'lateness_score' in df.columns else 0
    
    m1, m2, m3 = st.columns(3)
    m1.metric("‚è±Ô∏è ‡∏£‡∏≠‡∏ö‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (‡∏ó‡∏±‡πâ‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó)", f"{avg_cycle:.0f} ‡∏ß‡∏±‡∏ô")
    m2.metric("üê¢ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (Late Score)", f"{avg_late:.2f} ‡πÄ‡∏ó‡πà‡∏≤", "‡∏ñ‡πâ‡∏≤ > 1.0 ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ä‡πâ‡∏≤")
    m3.metric("üìÖ ‡∏ã‡∏∑‡πâ‡∏≠‡∏ã‡πâ‡∏≥‡πÉ‡∏ô 30 ‡∏ß‡∏±‡∏ô", f"{len(df[df['cat_median_days']<=30]):,} ‡∏Ñ‡∏ô")
    
    st.markdown("---")
    
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("üì¶ ‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠‡πÅ‡∏¢‡∏Å‡∏£‡∏≤‡∏¢‡∏´‡∏°‡∏ß‡∏î")
        if 'cat_median_days' in df.columns:
            cat_cyc = df.groupby('product_category_name')['cat_median_days'].median().reset_index().sort_values('cat_median_days').head(20)
            chart = alt.Chart(cat_cyc).mark_bar().encode(
                x=alt.X('cat_median_days', title='Days'), y=alt.Y('product_category_name', sort='x'),
                color=alt.Color('cat_median_days', scale=alt.Scale(scheme='tealblues'))
            )
            st.altair_chart(chart, use_container_width=True)
            
    with c2:
        st.subheader("üê¢ Distribution of Lateness")
        if 'lateness_score' in df.columns:
            hist_df = df[df['lateness_score'] <= 10]
            chart = alt.Chart(hist_df).mark_bar().encode(
                x=alt.X('lateness_score', bin=alt.Bin(maxbins=30)),
                y='count()',
                color=alt.condition(alt.datum.lateness_score > 3, alt.value('red'), alt.value('green'))
            )
            st.altair_chart(chart, use_container_width=True)
            
    st.subheader("üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≤‡∏¢‡∏´‡∏°‡∏ß‡∏î")
    summ = df.groupby('product_category_name').agg({
        'customer_unique_id':'count', 'cat_median_days':'mean', 'lateness_score':'mean', 'churn_probability':'mean'
    }).reset_index()
    st.dataframe(summ.sort_values('cat_median_days'), use_container_width=True, hide_index=True)
    # ... (‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ô Page 6 ‡πÄ‡∏î‡∏¥‡∏°) ...

    st.markdown("---")
    st.subheader("üìÖ Seasonal Patterns: ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏´‡∏ô?")
    st.caption("‡πÄ‡∏â‡∏î‡∏™‡∏µ‡πÄ‡∏Ç‡πâ‡∏° = ‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (High Season)")

    if 'order_purchase_timestamp' in df.columns:
        # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏î‡∏∂‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏≠‡∏≠‡∏Å‡∏°‡∏≤)
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Copy ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö df ‡∏´‡∏•‡∏±‡∏Å
        season_df = df.copy()
        season_df['month_num'] = season_df['order_purchase_timestamp'].dt.month
        season_df['month_name'] = season_df['order_purchase_timestamp'].dt.strftime('%b') # Jan, Feb, ...
        
        # 2. ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Group by Category & Month)
        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
        heatmap_data = season_df.groupby(['product_category_name', 'month_num', 'month_name']).size().reset_index(name='sales_volume')
        
        # 3. ‡∏Ñ‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Top Categories (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≤‡∏ü‡∏î‡∏π‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÑ‡∏°‡πà‡∏£‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ)
        # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 15 ‡∏´‡∏°‡∏ß‡∏î‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ô‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î
        top_cats = season_df['product_category_name'].value_counts().head(15).index.tolist()
        heatmap_data = heatmap_data[heatmap_data['product_category_name'].isin(top_cats)]
        
        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Heatmap Chart
        # ‡πÅ‡∏Å‡∏ô X: ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (Jan -> Dec)
        # ‡πÅ‡∏Å‡∏ô Y: ‡∏´‡∏°‡∏ß‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
        # ‡∏™‡∏µ: ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ (‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏°‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ)
        heatmap = alt.Chart(heatmap_data).mark_rect().encode(
            x=alt.X('month_name', 
                    sort=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], 
                    title='‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (Month)'),
            y=alt.Y('product_category_name', title='‡∏´‡∏°‡∏ß‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤'),
            color=alt.Color('sales_volume', 
                            scale=alt.Scale(scheme='orangered'), # ‡∏™‡∏µ‡∏™‡πâ‡∏°-‡πÅ‡∏î‡∏á (‡∏£‡πâ‡∏≠‡∏ô‡πÅ‡∏£‡∏á)
                            title='‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ (Orders)'),
            tooltip=['product_category_name', 'month_name', alt.Tooltip('sales_volume', format=',')]
        ).properties(
            height=500,
            title='üî• Heatmap ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ Top 15'
        )
        
        st.altair_chart(heatmap, use_container_width=True)
        
        st.info("üí° **Tip:** ‡∏•‡∏≠‡∏á‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏™‡∏µ‡πÅ‡∏î‡∏á‡πÄ‡∏Ç‡πâ‡∏°‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏ï‡πá‡∏≠‡∏Å‡∏Ç‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏¥‡∏á‡πÅ‡∏≠‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏´‡∏ô")
        
    else:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (order_purchase_timestamp) ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Seasonality ‡πÑ‡∏î‡πâ")















